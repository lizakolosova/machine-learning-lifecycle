{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Mushroom Classification - Data Preprocessing Pipeline\n",
    "\n",
    "## Overview\n",
    "This notebook implements a robust preprocessing pipeline that:\n",
    "1. Handles missing values without data leakage\n",
    "2. Encodes categorical features with justification\n",
    "3. Handles rare categories appropriately\n",
    "4. Performs feature selection\n",
    "5. Creates a production-ready sklearn Pipeline"
   ],
   "id": "overview"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T22:31:34.238274Z",
     "start_time": "2026-02-04T22:31:34.229452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, mutual_info_classif\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "id": "imports",
   "outputs": [],
<<<<<<< HEAD
=======
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T15:40:45.462347Z",
     "start_time": "2025-10-25T15:40:45.406366Z"
    }
   },
   "cell_type": "code",
   "source": "df_mushrooms = pd.read_csv(\"artifacts/mushrooms_clean.csv\")",
   "id": "3ca42212e1059e0b",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T15:40:46.481375Z",
     "start_time": "2025-10-25T15:40:46.447879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "missing_cols = df_mushrooms.columns[df_mushrooms.isnull().any()].tolist()\n",
    "# Drop rows with missing values (if few)\n",
    "if df_mushrooms.isnull().sum().max() < len(df_mushrooms) * 0.05:  # Less than 5%\n",
    "    df_mushrooms = df_mushrooms.dropna()\n",
    "    print(f\"Dropped rows with missing values. New shape: {df_mushrooms.shape}\")\n",
    "\n",
    "# Or Impute with mode (most common category)\n",
    "else:\n",
    "    for col in missing_cols:\n",
    "        mode_value = df_mushrooms[col].mode()[0]\n",
    "        df_mushrooms[col].fillna(mode_value, inplace=True)\n",
    "        print(f\"Filled {col} missing values with mode: {mode_value}\")"
   ],
   "id": "3b680100ea43b9b1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped rows with missing values. New shape: (8124, 23)\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T15:40:48.017045Z",
     "start_time": "2025-10-25T15:40:48.000651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\nMissing values after handling:\")\n",
    "print(df_mushrooms.isna().sum())"
   ],
   "id": "1fb6a6bd160b9cf2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values after handling:\n",
      "class                       0\n",
      "cap-shape                   0\n",
      "cap-surface                 0\n",
      "cap-color                   0\n",
      "bruises                     0\n",
      "odor                        0\n",
      "gill-attachment             0\n",
      "gill-spacing                0\n",
      "gill-size                   0\n",
      "gill-color                  0\n",
      "stalk-shape                 0\n",
      "stalk-root                  0\n",
      "stalk-surface-above-ring    0\n",
      "stalk-surface-below-ring    0\n",
      "stalk-color-above-ring      0\n",
      "stalk-color-below-ring      0\n",
      "veil-type                   0\n",
      "veil-color                  0\n",
      "ring-number                 0\n",
      "ring-type                   0\n",
      "spore-print-color           0\n",
      "population                  0\n",
      "habitat                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T15:40:49.785166Z",
     "start_time": "2025-10-25T15:40:49.753017Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# SPLIT DATA FIRST (before encoding)\n",
    "X = df_mushrooms.drop('class', axis=1)  # Assuming 'class' is target\n",
    "y = df_mushrooms['class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y  # Keep class balance in both sets\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")"
   ],
   "id": "1fcc8b4ad1a84bcf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set: (6499, 22)\n",
      "Test set: (1625, 22)\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T15:40:54.085850Z",
     "start_time": "2025-10-25T15:40:51.018503Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ENCODE CATEGORICAL FEATURES (fit on train, transform on test)\n",
    "print(\"\\n=== Label Encoding ===\")\n",
    "\n",
    "# Create dictionary to store encoders for each column\n",
    "label_encoders = {}\n",
    "X_train_encoded = pd.DataFrame()\n",
    "X_test_encoded = pd.DataFrame()\n",
    "\n",
    "for column in X_train.columns:\n",
    "    # Create and fit encoder on TRAINING data only\n",
    "    le = LabelEncoder()\n",
    "    X_train_encoded[column] = le.fit_transform(X_train[column])\n",
    "\n",
    "    # Transform test data using the SAME encoder\n",
    "    # Handle unseen categories gracefully, If test has unseen category → use -1\n",
    "    X_test_encoded[column] = X_test[column].map(\n",
    "        lambda x: le.transform([x])[0] if x in le.classes_ else -1\n",
    "    )\n",
    "    # Store encoder for later use\n",
    "    label_encoders[column] = le\n",
    "\n",
    "    print(f\"{column}: {len(le.classes_)} classes\")\n",
    "\n",
    "\n",
    "# Encode target variable\n",
    "y_encoder = LabelEncoder()\n",
    "y_train_encoded = y_encoder.fit_transform(y_train)\n",
    "y_test_encoded = y_encoder.transform(y_test)\n",
    "\n",
    "print(f\"Target classes: {y_encoder.classes_}\")\n",
    "print(f\"y_train_encoded shape: {y_train_encoded.shape}\")\n",
    "print(f\"y_test_encoded shape: {y_test_encoded.shape}\")\n"
   ],
   "id": "d7cdd4df10191e44",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Label Encoding ===\n",
      "cap-shape: 6 classes\n",
      "cap-surface: 4 classes\n",
      "cap-color: 10 classes\n",
      "bruises: 2 classes\n",
      "odor: 9 classes\n",
      "gill-attachment: 2 classes\n",
      "gill-spacing: 2 classes\n",
      "gill-size: 2 classes\n",
      "gill-color: 12 classes\n",
      "stalk-shape: 2 classes\n",
      "stalk-root: 5 classes\n",
      "stalk-surface-above-ring: 4 classes\n",
      "stalk-surface-below-ring: 4 classes\n",
      "stalk-color-above-ring: 9 classes\n",
      "stalk-color-below-ring: 9 classes\n",
      "veil-type: 1 classes\n",
      "veil-color: 4 classes\n",
      "ring-number: 3 classes\n",
      "ring-type: 5 classes\n",
      "spore-print-color: 9 classes\n",
      "population: 6 classes\n",
      "habitat: 7 classes\n",
      "Target classes: ['e' 'p']\n",
      "y_train_encoded shape: (6499,)\n",
      "y_test_encoded shape: (1625,)\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "eaf7112b2490164f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T15:40:56.199899Z",
     "start_time": "2025-10-25T15:40:56.184744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Final check\n",
    "print(\"\\n=== Final Encoded Data ===\")\n",
    "print(\"Training features shape:\", X_train_encoded.shape)\n",
    "print(\"Test features shape:\", X_test_encoded.shape)\n",
    "print(\"\\nSample of encoded training data:\")\n",
    "print(X_train_encoded.head())\n",
    "print(\"\\nNo missing values in encoded data:\")\n",
    "print(X_train_encoded.isnull().sum().sum() == 0)"
   ],
   "id": "ec18441d137a945",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Final Encoded Data ===\n",
      "Training features shape: (6499, 22)\n",
      "Test features shape: (1625, 22)\n",
      "\n",
      "Sample of encoded training data:\n",
      "   cap-shape  cap-surface  cap-color  bruises  odor  gill-attachment  \\\n",
      "0          2            3          9        0     2                1   \n",
      "1          5            2          5        1     5                1   \n",
      "2          0            2          3        0     5                1   \n",
      "3          2            2          4        0     7                1   \n",
      "4          3            3          4        0     2                1   \n",
      "\n",
      "   gill-spacing  gill-size  gill-color  stalk-shape  ...  \\\n",
      "0             0          0           2            0  ...   \n",
      "1             0          0           1            0  ...   \n",
      "2             1          0          10            0  ...   \n",
      "3             0          1           0            1  ...   \n",
      "4             0          1           0            1  ...   \n",
      "\n",
      "   stalk-surface-below-ring  stalk-color-above-ring  stalk-color-below-ring  \\\n",
      "0                         1                       6                       0   \n",
      "1                         2                       2                       7   \n",
      "2                         2                       7                       7   \n",
      "3                         1                       6                       7   \n",
      "4                         1                       6                       6   \n",
      "\n",
      "   veil-type  veil-color  ring-number  ring-type  spore-print-color  \\\n",
      "0          0           2            1          2                  1   \n",
      "1          0           2            2          0                  7   \n",
      "2          0           2            2          4                  7   \n",
      "3          0           2            1          0                  7   \n",
      "4          0           2            1          0                  7   \n",
      "\n",
      "   population  habitat  \n",
      "0           5        1  \n",
      "1           1        6  \n",
      "2           3        1  \n",
      "3           4        0  \n",
      "4           4        4  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "\n",
      "No missing values in encoded data:\n",
      "True\n"
     ]
    }
   ],
>>>>>>> origin/main
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Load Data and Initial Split\n",
    "\n",
    "### Critical Principle: Prevent Data Leakage\n",
    "We split the data BEFORE any preprocessing to ensure:\n",
    "- Training data statistics don't contaminate test set\n",
    "- Imputation values come only from training data\n",
    "- Encoding categories are learned only from training data\n",
    "- Feature selection is based only on training data patterns"
   ],
   "id": "load_data_header"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T22:31:34.399418Z",
     "start_time": "2026-02-04T22:31:34.369225Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_mushrooms = pd.read_csv(\"artifacts/mushrooms_clean.csv\")\n",
    "\n",
    "print(f\"Dataset shape: {df_mushrooms.shape}\")\n",
    "print(f\"Features: {df_mushrooms.shape[1] - 1}\")\n",
    "print(f\"Samples: {df_mushrooms.shape[0]}\")"
   ],
   "id": "load_data",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (8124, 23)\n",
      "Features: 22\n",
      "Samples: 8124\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Train-Test Split (BEFORE Preprocessing)\n",
    "\n",
    "### Why Split First?\n",
    "Splitting BEFORE preprocessing prevents **data leakage** - the most common mistake in ML pipelines."
   ],
   "id": "split_explanation"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T22:31:34.533046Z",
     "start_time": "2026-02-04T22:31:34.501660Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = df_mushrooms.drop('class', axis=1)\n",
    "y = df_mushrooms['class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "print(f\"\\nClass distribution in train: {y_train.value_counts().to_dict()}\")\n",
    "print(f\"Class distribution in test: {y_test.value_counts().to_dict()}\")"
   ],
   "id": "train_test_split",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (6499, 22)\n",
      "Test set: (1625, 22)\n",
      "\n",
      "Class distribution in train: {'e': 3366, 'p': 3133}\n",
      "Class distribution in test: {'e': 842, 'p': 783}\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Handling Rare Categories\n",
    "\n",
    "### Problem:\n",
    "Some categorical values appear very rarely (<1% of samples). This causes issues:\n",
    "- May not appear in test set → encoding errors\n",
    "- Insufficient samples for model to learn patterns\n",
    "- Can lead to overfitting\n",
    "\n",
    "### Solution:\n",
    "We'll identify rare categories and configure our encoder to handle them gracefully."
   ],
   "id": "rare_categories_header"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T22:31:34.577429Z",
     "start_time": "2026-02-04T22:31:34.537857Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def identify_rare_categories(X, threshold=0.01):\n",
    "    rare_categories = {}\n",
    "    min_count = int(threshold * len(X))\n",
    "    \n",
    "    for col in X.columns:\n",
    "        value_counts = X[col].value_counts()\n",
    "        rare_values = value_counts[value_counts < min_count].index.tolist()\n",
    "        \n",
    "        if rare_values:\n",
    "            rare_categories[col] = rare_values\n",
    "    \n",
    "    return rare_categories\n",
    "\n",
    "rare_cats = identify_rare_categories(X_train, threshold=0.01)\n",
    "\n",
    "if rare_cats:\n",
    "    print(\"Rare categories found (appearing in <1% of training samples):\\n\")\n",
    "    for col, values in rare_cats.items():\n",
    "        print(f\"{col}: {values}\")\n",
    "else:\n",
    "    print(\"No rare categories found in training data.\")"
   ],
   "id": "rare_categories",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rare categories found (appearing in <1% of training samples):\n",
      "\n",
      "cap-shape: ['s', 'c']\n",
      "cap-surface: ['g']\n",
      "cap-color: ['c', 'r', 'u']\n",
      "odor: ['m']\n",
      "gill-color: ['o', 'r']\n",
      "stalk-surface-above-ring: ['y']\n",
      "stalk-color-above-ring: ['c', 'y']\n",
      "stalk-color-below-ring: ['c', 'y']\n",
      "veil-color: ['y']\n",
      "ring-number: ['n']\n",
      "ring-type: ['f', 'n']\n",
      "spore-print-color: ['r', 'y', 'o', 'b', 'u']\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Handling Strategy:\n",
    "- OrdinalEncoder with handle_unknown='use_encoded_value'\n",
    "- Unseen categories in test set will be assigned a special value (-1)\n",
    "- This prevents errors while allowing model to recognize 'unknown' patterns"
   ],
   "id": "6f3afbfed9ca4b9b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Encoding Strategy & Justification\n",
    "\n",
    "### Our Choice: OrdinalEncoder\n",
    "**Justification**:\n",
    "- We're using tree-based models (Decision Tree, Random Forest) that handle ordinal encoding well\n",
    "- Need production-ready pipeline that can be deployed\n",
    "- Must handle unknown categories in production\n",
    "- Avoid high dimensionality from one-hot encoding (22 features → potentially 100+ columns)"
   ],
   "id": "encoding_justification"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. Build Preprocessing Pipeline\n",
    "\n",
    "### Pipeline Components:\n",
    "1. **SimpleImputer**: Handle missing values with mode (most frequent)\n",
    "2. **OrdinalEncoder**: Convert categories to numbers, handle unknowns\n",
    "3. **VarianceThreshold**: Remove features with near-zero variance\n",
    "4. **SelectKBest**: Select top K features using mutual information"
   ],
   "id": "pipeline_explanation"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T22:31:34.686386Z",
     "start_time": "2026-02-04T22:31:34.680852Z"
    }
   },
   "cell_type": "code",
   "source": [
    "categorical_features = X_train.columns.tolist()\n",
    "\n",
    "encoder = Pipeline([\n",
    "    ('imputer', SimpleImputer(\n",
    "        strategy='most_frequent',\n",
    "    )),\n",
    "    ('ordinal', OrdinalEncoder(\n",
    "        handle_unknown='use_encoded_value',\n",
    "        unknown_value=-1,\n",
    "    ))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', encoder, categorical_features)\n",
    "], remainder='passthrough')"
   ],
   "id": "build_encoder",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Why SimpleImputer with 'most_frequent'?\n",
    "\n",
    "**Justification**:\n",
    "- `stalk-root` has ~30% missing values (represented as '?')\n",
    "- For categorical data, mode (most frequent value) is a sensible default\n",
    "- Alternative strategies:\n",
    "  - Create 'missing' category → Increases dimensionality, may help if missingness is informative\n",
    "  - Drop feature → Loses potentially useful information\n",
    "  - Drop rows → Loses 30% of data, not acceptable\n",
    "- Mode imputation is simple, doesn't add complexity, and is fitted only on training data (no leakage)"
   ],
   "id": "imputation_justification"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T22:31:34.813876Z",
     "start_time": "2026-02-04T22:31:34.801919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prep_pipeline = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('variance', VarianceThreshold(threshold=0.01)),\n",
    "    ('select_kbest', SelectKBest(\n",
    "        score_func=mutual_info_classif,\n",
    "        k=15\n",
    "    ))\n",
    "])\n",
    "\n",
    "print(\"  Pipeline steps:\")\n",
    "for i, (name, step) in enumerate(prep_pipeline.steps, 1):\n",
    "    print(f\"  {i}. {name}: {type(step).__name__}\")"
   ],
   "id": "full_pipeline",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Pipeline steps:\n",
      "  1. preprocess: ColumnTransformer\n",
      "  2. variance: VarianceThreshold\n",
      "  3. select_kbest: SelectKBest\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Feature Selection Justification\n",
    "\n",
    "**VarianceThreshold (threshold=0.01)**:\n",
    "- Removes features where almost all values are the same\n",
    "- Example: `veil-type` has only one value in the entire dataset\n",
    "- Such features provide zero information for classification\n",
    "- Threshold of 1% means \"remove if 99% of values are identical\"\n",
    "\n",
    "**SelectKBest with Mutual Information**:\n",
    "- Mutual Information measures how much knowing a feature reduces uncertainty about the target\n",
    "- Well-suited for categorical features (unlike correlation which assumes linearity)\n",
    "- k=15 selected based on EDA showing ~15 highly informative features\n",
    "- Reduces dimensionality while keeping most discriminative features"
   ],
   "id": "feature_selection_justification"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6. Encode Target Variable"
   ],
   "id": "encode_target_header"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T22:31:35.034600Z",
     "start_time": "2026-02-04T22:31:35.023390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_encoder = LabelEncoder()\n",
    "y_train_encoded = y_encoder.fit_transform(y_train)\n",
    "y_test_encoded = y_encoder.transform(y_test)\n",
    "\n",
    "print(f\"Target classes: {y_encoder.classes_}\")\n",
    "print(f\"Encoded as: {dict(zip(y_encoder.classes_, y_encoder.transform(y_encoder.classes_)))}\")\n",
    "print(f\"\\ny_train shape: {y_train_encoded.shape}\")\n",
    "print(f\"y_test shape: {y_test_encoded.shape}\")"
   ],
   "id": "encode_target",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target classes: ['e' 'p']\n",
      "Encoded as: {'e': 0, 'p': 1}\n",
      "\n",
      "y_train shape: (6499,)\n",
      "y_test shape: (1625,)\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 7. Fit Pipeline and Transform Data"
   ],
   "id": "fit_transform_header"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T22:31:35.886945Z",
     "start_time": "2026-02-04T22:31:35.053507Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prep_pipeline.fit(X_train, y_train_encoded)\n",
    "\n",
    "X_train_final = prep_pipeline.transform(X_train)\n",
    "X_test_final = prep_pipeline.transform(X_test)\n",
    "\n",
    "print(f\"\\nOriginal shape: {X_train.shape}\")\n",
    "print(f\"Final training shape: {X_train_final.shape}\")\n",
    "print(f\"Final test shape: {X_test_final.shape}\")\n",
    "print(f\"\\nFeatures reduced from {X_train.shape[1]} to {X_train_final.shape[1]}\")"
   ],
   "id": "fit_transform",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original shape: (6499, 22)\n",
      "Final training shape: (6499, 15)\n",
      "Final test shape: (1625, 15)\n",
      "\n",
      "Features reduced from 22 to 15\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 8. Identify Selected Features"
   ],
   "id": "selected_features_header"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T22:31:36.027984Z",
     "start_time": "2026-02-04T22:31:36.009677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "vt = prep_pipeline.named_steps['variance']\n",
    "mask_var = vt.get_support()\n",
    "names_after_var = [n for n, keep in zip(categorical_features, mask_var) if keep]\n",
    "\n",
    "print(f\"After VarianceThreshold: {len(names_after_var)} features\")\n",
    "removed_by_variance = [n for n, keep in zip(categorical_features, mask_var) if not keep]\n",
    "if removed_by_variance:\n",
    "    print(f\"Removed (low variance): {removed_by_variance}\")\n",
    "\n",
    "skb = prep_pipeline.named_steps['select_kbest']\n",
    "mask_kbest = skb.get_support()\n",
    "selected_feature_names = [names_after_var[i] for i, keep in enumerate(mask_kbest) if keep]\n",
    "\n",
    "print(f\"\\nAfter SelectKBest: {len(selected_feature_names)} features\")\n",
    "print(f\"Selected features: {selected_feature_names}\")\n",
    "\n",
    "feature_scores = pd.DataFrame({\n",
    "    'Feature': names_after_var,\n",
    "    'Score': skb.scores_,\n",
    "    'Selected': mask_kbest\n",
    "}).sort_values('Score', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 features by Mutual Information score:\")\n",
    "print(feature_scores.head(10).to_string(index=False))"
   ],
   "id": "selected_features",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After VarianceThreshold: 21 features\n",
      "Removed (low variance): ['veil-type']\n",
      "\n",
      "After SelectKBest: 15 features\n",
      "Selected features: ['cap-shape', 'bruises', 'odor', 'gill-spacing', 'gill-size', 'gill-color', 'stalk-root', 'stalk-surface-above-ring', 'stalk-surface-below-ring', 'stalk-color-above-ring', 'stalk-color-below-ring', 'ring-type', 'spore-print-color', 'population', 'habitat']\n",
      "\n",
      "Top 10 features by Mutual Information score:\n",
      "                 Feature    Score  Selected\n",
      "                    odor 0.627656      True\n",
      "       spore-print-color 0.338620      True\n",
      "              gill-color 0.287922      True\n",
      "               ring-type 0.230082      True\n",
      "stalk-surface-above-ring 0.194155      True\n",
      "stalk-surface-below-ring 0.190835      True\n",
      "  stalk-color-above-ring 0.179182      True\n",
      "  stalk-color-below-ring 0.174242      True\n",
      "               gill-size 0.156172      True\n",
      "              population 0.145489      True\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 9. Verify Pipeline Integrity\n",
    "\n",
    "### Critical Check: No Data Leakage\n",
    "We verify that:\n",
    "1. Imputation used only training data statistics\n",
    "2. Feature selection used only training data patterns\n",
    "3. Test data was never used in any fitting step"
   ],
   "id": "verify_integrity_header"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T22:31:36.189105Z",
     "start_time": "2026-02-04T22:31:36.171625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_sample = X_test.iloc[[0]].copy()\n",
    "original_value = test_sample.iloc[0, 0]\n",
    "test_sample.iloc[0, 0] = 'UNKNOWN_CATEGORY_NOT_IN_TRAINING'\n",
    "\n",
    "try:\n",
    "    transformed = prep_pipeline.transform(test_sample)\n",
    "    print(f\"  Original value: {original_value}\")\n",
    "    print(f\"  Test value: UNKNOWN_CATEGORY_NOT_IN_TRAINING\")\n",
    "    print(f\"  Encoded as: {transformed[0, 0]} (special unknown value)\")\n",
    "except Exception as e:\n",
    "    print(f\"  Pipeline failed on unknown category: {e}\")\n",
    "\n",
    "imputer = prep_pipeline.named_steps['preprocess'].named_transformers_['cat'].named_steps['imputer']\n",
    "\n",
    "print(f\"  Imputer was fitted on {len(X_train)} training samples only\")\n",
    "print(f\"  Test set has {len(X_test)} samples that were never seen during fitting\")"
   ],
   "id": "verify_integrity",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Original value: x\n",
      "  Test value: UNKNOWN_CATEGORY_NOT_IN_TRAINING\n",
      "  Encoded as: -1.0 (special unknown value)\n",
      "  Imputer was fitted on 6499 training samples only\n",
      "  Test set has 1625 samples that were never seen during fitting\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 10. Save Preprocessing Artifacts"
   ],
   "id": "save_artifacts_header"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T22:32:12.872871Z",
     "start_time": "2026-02-04T22:32:12.827896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.makedirs('artifacts', exist_ok=True)\n",
    "\n",
    "prep_package = {\n",
    "    \"pipeline\": prep_pipeline,\n",
    "    \"original_feature_names\": categorical_features,\n",
    "    \"selected_feature_names\": selected_feature_names,\n",
    "    \"target_encoder\": y_encoder,\n",
    "    \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"rare_categories\": rare_cats,\n",
    "    \"preprocessing_info\": {\n",
    "        \"imputation_strategy\": \"most_frequent\",\n",
    "        \"encoding_method\": \"OrdinalEncoder\",\n",
    "        \"handle_unknown\": \"use_encoded_value (value=-1)\",\n",
    "        \"variance_threshold\": 0.01,\n",
    "        \"feature_selection\": \"SelectKBest (mutual_info_classif, k=15)\",\n",
    "        \"features_before\": X_train.shape[1],\n",
    "        \"features_after\": X_train_final.shape[1]\n",
    "    }\n",
    "}\n",
    "\n",
    "joblib.dump(prep_package, \"artifacts/mushroom_preprocessing_pipeline.pkl\")\n",
    "joblib.dump(X_train_final, \"artifacts/X_train_final.pkl\")\n",
    "joblib.dump(X_test_final, \"artifacts/X_test_final.pkl\")\n",
    "joblib.dump(y_train_encoded, \"artifacts/y_train_encoded.pkl\")\n",
    "joblib.dump(y_test_encoded, \"artifacts/y_test_encoded.pkl\")\n",
    "\n",
    "print(\"PREPROCESSING SUMMARY\")\n",
    "for key, value in prep_package['preprocessing_info'].items():\n",
    "    print(f\"{key.replace('_', ' ').title()}: {value}\")"
   ],
   "id": "save_artifacts",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREPROCESSING SUMMARY\n",
      "Imputation Strategy: most_frequent\n",
      "Encoding Method: OrdinalEncoder\n",
      "Handle Unknown: use_encoded_value (value=-1)\n",
      "Variance Threshold: 0.01\n",
      "Feature Selection: SelectKBest (mutual_info_classif, k=15)\n",
      "Features Before: 22\n",
      "Features After: 15\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 11. Key Takeaways\n",
    "\n",
    "### What We Did Right:\n",
    "1. **Split data BEFORE preprocessing** - prevents data leakage\n",
    "2. **Used sklearn Pipeline** - production-ready, prevents leakage, reproducible\n",
    "3. **Handled rare categories** - robust to unseen values in production\n",
    "4. **Justified all choices** - imputation strategy, encoding method, feature selection\n",
    "5. **Used appropriate encoding** - OrdinalEncoder for tree-based models, not LabelEncoder"
   ],
   "id": "key_takeaways"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
