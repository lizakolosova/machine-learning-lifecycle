{
 "cells": [
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-25T15:40:44.521608Z",
     "start_time": "2025-10-25T15:40:44.512847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import f1_score\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, mutual_info_classif\n",
    "from sklearn.impute import SimpleImputer"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T15:40:45.462347Z",
     "start_time": "2025-10-25T15:40:45.406366Z"
    }
   },
   "cell_type": "code",
   "source": "df_mushrooms = pd.read_csv(\"artifacts/mushrooms_clean.csv\")",
   "id": "3ca42212e1059e0b",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T15:40:46.481375Z",
     "start_time": "2025-10-25T15:40:46.447879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "missing_cols = df_mushrooms.columns[df_mushrooms.isnull().any()].tolist()\n",
    "# Drop rows with missing values (if few)\n",
    "if df_mushrooms.isnull().sum().max() < len(df_mushrooms) * 0.05:  # Less than 5%\n",
    "    df_mushrooms = df_mushrooms.dropna()\n",
    "    print(f\"Dropped rows with missing values. New shape: {df_mushrooms.shape}\")\n",
    "\n",
    "# Or Impute with mode (most common category)\n",
    "else:\n",
    "    for col in missing_cols:\n",
    "        mode_value = df_mushrooms[col].mode()[0]\n",
    "        df_mushrooms[col].fillna(mode_value, inplace=True)\n",
    "        print(f\"Filled {col} missing values with mode: {mode_value}\")"
   ],
   "id": "3b680100ea43b9b1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped rows with missing values. New shape: (8124, 23)\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T15:40:48.017045Z",
     "start_time": "2025-10-25T15:40:48.000651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\nMissing values after handling:\")\n",
    "print(df_mushrooms.isna().sum())"
   ],
   "id": "1fb6a6bd160b9cf2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values after handling:\n",
      "class                       0\n",
      "cap-shape                   0\n",
      "cap-surface                 0\n",
      "cap-color                   0\n",
      "bruises                     0\n",
      "odor                        0\n",
      "gill-attachment             0\n",
      "gill-spacing                0\n",
      "gill-size                   0\n",
      "gill-color                  0\n",
      "stalk-shape                 0\n",
      "stalk-root                  0\n",
      "stalk-surface-above-ring    0\n",
      "stalk-surface-below-ring    0\n",
      "stalk-color-above-ring      0\n",
      "stalk-color-below-ring      0\n",
      "veil-type                   0\n",
      "veil-color                  0\n",
      "ring-number                 0\n",
      "ring-type                   0\n",
      "spore-print-color           0\n",
      "population                  0\n",
      "habitat                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T15:40:49.785166Z",
     "start_time": "2025-10-25T15:40:49.753017Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# SPLIT DATA FIRST (before encoding)\n",
    "X = df_mushrooms.drop('class', axis=1)  # Assuming 'class' is target\n",
    "y = df_mushrooms['class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y  # Keep class balance in both sets\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")"
   ],
   "id": "1fcc8b4ad1a84bcf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set: (6499, 22)\n",
      "Test set: (1625, 22)\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T15:40:54.085850Z",
     "start_time": "2025-10-25T15:40:51.018503Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ENCODE CATEGORICAL FEATURES (fit on train, transform on test)\n",
    "print(\"\\n=== Label Encoding ===\")\n",
    "\n",
    "# Create dictionary to store encoders for each column\n",
    "label_encoders = {}\n",
    "X_train_encoded = pd.DataFrame()\n",
    "X_test_encoded = pd.DataFrame()\n",
    "\n",
    "for column in X_train.columns:\n",
    "    # Create and fit encoder on TRAINING data only\n",
    "    le = LabelEncoder()\n",
    "    X_train_encoded[column] = le.fit_transform(X_train[column])\n",
    "\n",
    "    # Transform test data using the SAME encoder\n",
    "    # Handle unseen categories gracefully, If test has unseen category ‚Üí use -1\n",
    "    X_test_encoded[column] = X_test[column].map(\n",
    "        lambda x: le.transform([x])[0] if x in le.classes_ else -1\n",
    "    )\n",
    "    # Store encoder for later use\n",
    "    label_encoders[column] = le\n",
    "\n",
    "    print(f\"{column}: {len(le.classes_)} classes\")\n",
    "\n",
    "\n",
    "# 7. Encode target variable\n",
    "y_encoder = LabelEncoder()\n",
    "y_train_encoded = y_encoder.fit_transform(y_train)\n",
    "y_test_encoded = y_encoder.transform(y_test)\n",
    "\n",
    "print(f\"Target classes: {y_encoder.classes_}\")\n",
    "print(f\"y_train_encoded shape: {y_train_encoded.shape}\")\n",
    "print(f\"y_test_encoded shape: {y_test_encoded.shape}\")\n"
   ],
   "id": "d7cdd4df10191e44",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Label Encoding ===\n",
      "cap-shape: 6 classes\n",
      "cap-surface: 4 classes\n",
      "cap-color: 10 classes\n",
      "bruises: 2 classes\n",
      "odor: 9 classes\n",
      "gill-attachment: 2 classes\n",
      "gill-spacing: 2 classes\n",
      "gill-size: 2 classes\n",
      "gill-color: 12 classes\n",
      "stalk-shape: 2 classes\n",
      "stalk-root: 5 classes\n",
      "stalk-surface-above-ring: 4 classes\n",
      "stalk-surface-below-ring: 4 classes\n",
      "stalk-color-above-ring: 9 classes\n",
      "stalk-color-below-ring: 9 classes\n",
      "veil-type: 1 classes\n",
      "veil-color: 4 classes\n",
      "ring-number: 3 classes\n",
      "ring-type: 5 classes\n",
      "spore-print-color: 9 classes\n",
      "population: 6 classes\n",
      "habitat: 7 classes\n",
      "Target classes: ['e' 'p']\n",
      "y_train_encoded shape: (6499,)\n",
      "y_test_encoded shape: (1625,)\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "eaf7112b2490164f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T15:40:56.199899Z",
     "start_time": "2025-10-25T15:40:56.184744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Final check\n",
    "print(\"\\n=== Final Encoded Data ===\")\n",
    "print(\"Training features shape:\", X_train_encoded.shape)\n",
    "print(\"Test features shape:\", X_test_encoded.shape)\n",
    "print(\"\\nSample of encoded training data:\")\n",
    "print(X_train_encoded.head())\n",
    "print(\"\\nNo missing values in encoded data:\")\n",
    "print(X_train_encoded.isnull().sum().sum() == 0)"
   ],
   "id": "ec18441d137a945",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Final Encoded Data ===\n",
      "Training features shape: (6499, 22)\n",
      "Test features shape: (1625, 22)\n",
      "\n",
      "Sample of encoded training data:\n",
      "   cap-shape  cap-surface  cap-color  bruises  odor  gill-attachment  \\\n",
      "0          2            3          9        0     2                1   \n",
      "1          5            2          5        1     5                1   \n",
      "2          0            2          3        0     5                1   \n",
      "3          2            2          4        0     7                1   \n",
      "4          3            3          4        0     2                1   \n",
      "\n",
      "   gill-spacing  gill-size  gill-color  stalk-shape  ...  \\\n",
      "0             0          0           2            0  ...   \n",
      "1             0          0           1            0  ...   \n",
      "2             1          0          10            0  ...   \n",
      "3             0          1           0            1  ...   \n",
      "4             0          1           0            1  ...   \n",
      "\n",
      "   stalk-surface-below-ring  stalk-color-above-ring  stalk-color-below-ring  \\\n",
      "0                         1                       6                       0   \n",
      "1                         2                       2                       7   \n",
      "2                         2                       7                       7   \n",
      "3                         1                       6                       7   \n",
      "4                         1                       6                       6   \n",
      "\n",
      "   veil-type  veil-color  ring-number  ring-type  spore-print-color  \\\n",
      "0          0           2            1          2                  1   \n",
      "1          0           2            2          0                  7   \n",
      "2          0           2            2          4                  7   \n",
      "3          0           2            1          0                  7   \n",
      "4          0           2            1          0                  7   \n",
      "\n",
      "   population  habitat  \n",
      "0           5        1  \n",
      "1           1        6  \n",
      "2           3        1  \n",
      "3           4        0  \n",
      "4           4        4  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "\n",
      "No missing values in encoded data:\n",
      "True\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Feature Engineering",
   "id": "651e477ce8074283"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 1. Feature Transformation\n",
    "Tree-based artifacts (Random Forest, XGBoost) don't need scaling, but linear artifacts (Logistic Regression, SVM) do. So we don't need scaling\n"
   ],
   "id": "a43aaac74e0c97bd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2. Feature Selection (Mutual Information (Information Gain))",
   "id": "59280ad6f3b105a5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T15:40:58.986776Z",
     "start_time": "2025-10-25T15:40:58.192460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\n=== Mutual Information Feature Selection ===\")\n",
    "\n",
    "# Calculate mutual information scores\n",
    "mi_scores = mutual_info_classif(X_train_encoded, y_train_encoded, random_state=42)\n",
    "\n",
    "# Create DataFrame\n",
    "mi_scores_df = pd.DataFrame({\n",
    "    'feature': X_train_encoded.columns,\n",
    "    'mi_score': mi_scores\n",
    "}).sort_values('mi_score', ascending=False)\n",
    "\n",
    "print(mi_scores_df)\n",
    "\n",
    "# Select top features (e.g., MI score > 0.1 or top 15)\n",
    "top_mi_features = mi_scores_df[mi_scores_df['mi_score'] > 0.1]['feature'].tolist()\n",
    "# OR: top_mi_features = mi_scores_df.head(15)['feature'].tolist()\n",
    "\n",
    "print(f\"\\nSelected {len(top_mi_features)} features with high mutual information\")\n",
    "\n",
    "X_train_mi = X_train_encoded[top_mi_features]\n",
    "X_test_mi = X_test_encoded[top_mi_features]"
   ],
   "id": "af511fe2b95c6c4d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Mutual Information Feature Selection ===\n",
      "                     feature  mi_score\n",
      "4                       odor  0.628823\n",
      "19         spore-print-color  0.340945\n",
      "8                 gill-color  0.293498\n",
      "18                 ring-type  0.211812\n",
      "12  stalk-surface-below-ring  0.198337\n",
      "11  stalk-surface-above-ring  0.197850\n",
      "13    stalk-color-above-ring  0.178775\n",
      "14    stalk-color-below-ring  0.164071\n",
      "7                  gill-size  0.152748\n",
      "20                population  0.144867\n",
      "3                    bruises  0.133102\n",
      "21                   habitat  0.111289\n",
      "10                stalk-root  0.102563\n",
      "6               gill-spacing  0.072009\n",
      "0                  cap-shape  0.038777\n",
      "17               ring-number  0.027028\n",
      "2                  cap-color  0.024342\n",
      "1                cap-surface  0.013465\n",
      "16                veil-color  0.012598\n",
      "9                stalk-shape  0.009762\n",
      "5            gill-attachment  0.008248\n",
      "15                 veil-type  0.001011\n",
      "\n",
      "Selected 13 features with high mutual information\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T15:41:00.472231Z",
     "start_time": "2025-10-25T15:41:00.150303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ========================================\n",
    "# FEATURE IMPORTANCE SELECTION\n",
    "# ========================================\n",
    "print(\"\\n=== Step 2: Feature Importance Selection ===\")\n",
    "\n",
    "# Train RF to get importances\n",
    "rf_temp = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_temp.fit(X_train_encoded, y_train_encoded)\n",
    "\n",
    "# Get importances\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train_encoded.columns,\n",
    "    'importance': rf_temp.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(feature_importance)\n",
    "\n",
    "# Select top 15 features\n",
    "top_important_features = feature_importance.head(15)['feature'].tolist()\n",
    "print(f\"\\nSelected {len(top_important_features)} most important features\")\n",
    "\n",
    "X_train_important = X_train_encoded[top_important_features]\n",
    "X_test_important = X_test_encoded[top_important_features]"
   ],
   "id": "82c67577da5f1905",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Step 2: Feature Importance Selection ===\n",
      "                     feature  importance\n",
      "4                       odor    0.193744\n",
      "8                 gill-color    0.114487\n",
      "19         spore-print-color    0.106751\n",
      "7                  gill-size    0.098617\n",
      "18                 ring-type    0.070559\n",
      "10                stalk-root    0.067075\n",
      "20                population    0.056547\n",
      "11  stalk-surface-above-ring    0.052588\n",
      "3                    bruises    0.046456\n",
      "12  stalk-surface-below-ring    0.028409\n",
      "21                   habitat    0.027418\n",
      "6               gill-spacing    0.025004\n",
      "13    stalk-color-above-ring    0.024496\n",
      "17               ring-number    0.019239\n",
      "14    stalk-color-below-ring    0.017353\n",
      "2                  cap-color    0.016126\n",
      "9                stalk-shape    0.015122\n",
      "1                cap-surface    0.009579\n",
      "0                  cap-shape    0.003882\n",
      "5            gill-attachment    0.003327\n",
      "16                veil-color    0.003219\n",
      "15                 veil-type    0.000000\n",
      "\n",
      "Selected 15 most important features\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3. Feature Creation (Interaction Features)",
   "id": "b9ab7b30495a42f9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T15:41:02.695076Z",
     "start_time": "2025-10-25T15:41:02.675869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ========================================\n",
    "# INTERACTION FEATURES\n",
    "# ========================================\n",
    "print(\"\\n===  Creating Interaction Features ===\")\n",
    "\n",
    "X_train_interactions = X_train_encoded.copy()\n",
    "X_test_interactions = X_test_encoded.copy()\n",
    "\n",
    "# Create key interactions\n",
    "X_train_interactions['odor_x_gill-color'] = X_train_encoded['odor'] * X_train_encoded['gill-color']\n",
    "X_test_interactions['odor_x_gill-color'] = X_test_encoded['odor'] * X_test_encoded['gill-color']\n",
    "\n",
    "X_train_interactions['spore_x_gill'] = X_train_encoded['spore-print-color'] * X_train_encoded['gill-color']\n",
    "X_test_interactions['spore_x_gill'] = X_test_encoded['spore-print-color'] * X_test_encoded['gill-color']\n",
    "\n",
    "X_train_interactions['cap-shape_x_cap-color'] = X_train_encoded['cap-shape'] * X_train_encoded['cap-color']\n",
    "X_test_interactions['cap-shape_x_cap-color'] = X_test_encoded['cap-shape'] * X_test_encoded['cap-color']\n",
    "\n",
    "X_train_interactions['odor_x_stalk-root'] = X_train_encoded['odor'] * X_train_encoded['stalk-root']\n",
    "X_test_interactions['odor_x_stalk-root'] = X_test_encoded['odor'] * X_test_encoded['stalk-root']\n",
    "\n",
    "X_train_interactions['ring-number_x_ring-type'] = X_train_encoded['ring-number'] * X_train_encoded['ring-type']\n",
    "X_test_interactions['ring-number_x_ring-type'] = X_test_encoded['ring-number'] * X_test_encoded['ring-type']\n",
    "\n",
    "print(f\"Added {X_train_interactions.shape[1] - X_train_encoded.shape[1]} interaction features\")\n",
    "print(f\"Total features: {X_train_interactions.shape[1]}\")"
   ],
   "id": "179ed36aaaa37c06",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===  Creating Interaction Features ===\n",
      "Added 5 interaction features\n",
      "Total features: 27\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T15:41:04.889015Z",
     "start_time": "2025-10-25T15:41:04.862129Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ========================================\n",
    "# GROUPED FEATURES\n",
    "# ========================================\n",
    "print(\"\\n=== Creating Grouped Features ===\")\n",
    "\n",
    "X_train_grouped = X_train_encoded.copy()\n",
    "X_test_grouped = X_test_encoded.copy()\n",
    "\n",
    "# Group cap features\n",
    "cap_features = ['cap-shape', 'cap-surface', 'cap-color']\n",
    "X_train_grouped['cap_combined'] = X_train_encoded[cap_features].sum(axis=1)\n",
    "X_test_grouped['cap_combined'] = X_test_encoded[cap_features].sum(axis=1)\n",
    "\n",
    "# Group gill features\n",
    "gill_features = ['gill-attachment', 'gill-spacing', 'gill-size', 'gill-color']\n",
    "X_train_grouped['gill_combined'] = X_train_encoded[gill_features].sum(axis=1)\n",
    "X_test_grouped['gill_combined'] = X_test_encoded[gill_features].sum(axis=1)\n",
    "\n",
    "# Group stalk features\n",
    "stalk_features = [col for col in X_train_encoded.columns if 'stalk' in col]\n",
    "X_train_grouped['stalk_combined'] = X_train_encoded[stalk_features].sum(axis=1)\n",
    "X_test_grouped['stalk_combined'] = X_test_encoded[stalk_features].sum(axis=1)\n",
    "\n",
    "# Group veil features\n",
    "X_train_grouped['veil_combined'] = X_train_encoded['veil-type'] + X_train_encoded['veil-color']\n",
    "X_test_grouped['veil_combined'] = X_test_encoded['veil-type'] + X_test_encoded['veil-color']\n",
    "\n",
    "# Group ring features\n",
    "X_train_grouped['ring_combined'] = X_train_encoded['ring-number'] + X_train_encoded['ring-type']\n",
    "X_test_grouped['ring_combined'] = X_test_encoded['ring-number'] + X_test_encoded['ring-type']\n",
    "\n",
    "print(f\"Added {X_train_grouped.shape[1] - X_train_encoded.shape[1]} grouped features\")\n",
    "print(f\"Total features: {X_train_grouped.shape[1]}\")"
   ],
   "id": "fbb79c37daa40307",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Creating Grouped Features ===\n",
      "Added 5 grouped features\n",
      "Total features: 27\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### FEATURE EXTRACTION",
   "id": "337e7b6b6271a212"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T15:41:08.111285Z",
     "start_time": "2025-10-25T15:41:08.092829Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ========================================\n",
    "# PCA FEATURE EXTRACTION\n",
    "# ========================================\n",
    "print(\"\\n=== PCA Feature Extraction ===\")\n",
    "\n",
    "# Keep 95% of variance\n",
    "pca = PCA(n_components=0.95, random_state=42)\n",
    "X_train_pca = pca.fit_transform(X_train_encoded)\n",
    "X_test_pca = pca.transform(X_test_encoded)\n",
    "\n",
    "print(f\"Original features: {X_train_encoded.shape[1]}\")\n",
    "print(f\"PCA components: {X_train_pca.shape[1]}\")\n",
    "print(f\"Variance explained: {pca.explained_variance_ratio_.sum():.4f}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "pca_columns = [f'PC{i+1}' for i in range(X_train_pca.shape[1])]\n",
    "X_train_pca = pd.DataFrame(X_train_pca, columns=pca_columns)\n",
    "X_test_pca = pd.DataFrame(X_test_pca, columns=pca_columns)\n",
    "\n",
    "print(\"\\n‚úì All feature sets created!\")"
   ],
   "id": "61264083bd3f26cc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PCA Feature Extraction ===\n",
      "Original features: 22\n",
      "PCA components: 10\n",
      "Variance explained: 0.9512\n",
      "\n",
      "‚úì All feature sets created!\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T15:41:25.125085Z",
     "start_time": "2025-10-25T15:41:10.210745Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ========================================\n",
    "#  COMPARE ALL METHODS\n",
    "# ========================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPARING FEATURE ENGINEERING METHODS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results = []\n",
    "\n",
    "def clean_features(X_train, X_test, y_train, var_threshold=0.01, k=15):\n",
    "    vt = VarianceThreshold(threshold=var_threshold)\n",
    "    X_train_var = vt.fit_transform(X_train)\n",
    "    X_test_var  = vt.transform(X_test)\n",
    "    kept_var = X_train.columns[vt.get_support()]\n",
    "    X_train_var = pd.DataFrame(X_train_var, columns=kept_var)\n",
    "    X_test_var  = pd.DataFrame(X_test_var,  columns=kept_var)\n",
    "\n",
    "    selector = SelectKBest(score_func=mutual_info_classif, k=min(k, X_train_var.shape[1]))\n",
    "    X_train_sel = selector.fit_transform(X_train_var, y_train)\n",
    "    X_test_sel  = selector.transform(X_test_var)\n",
    "    kept = kept_var[selector.get_support()]\n",
    "\n",
    "    # Return DataFrames with reduced features\n",
    "    return (\n",
    "        pd.DataFrame(X_train_sel, columns=kept),\n",
    "        pd.DataFrame(X_test_sel,  columns=kept)\n",
    "    )\n",
    "\n",
    "\n",
    "def evaluate_features(X_tr, X_te, y_tr, y_te, method_name):\n",
    "    X_tr_clean, X_te_clean = clean_features(X_tr, X_te, y_tr, k=15)\n",
    "\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    cv_scores = cross_val_score(model, X_tr_clean, y_tr, cv=5, scoring='accuracy')\n",
    "    model.fit(X_tr_clean, y_tr)\n",
    "    y_pred = model.predict(X_te_clean)\n",
    "\n",
    "    test_acc = accuracy_score(y_te, y_pred)\n",
    "    test_f1 = f1_score(y_te, y_pred, average='weighted')\n",
    "\n",
    "    results.append({\n",
    "        'Method': method_name,\n",
    "        'Features Before': X_tr.shape[1],\n",
    "        'Features After': X_tr_clean.shape[1],\n",
    "        'CV Accuracy': cv_scores.mean(),\n",
    "        'Test Accuracy': test_acc,\n",
    "        'Test F1': test_f1\n",
    "    })\n",
    "\n",
    "    print(f\"\\n{method_name}:\")\n",
    "    print(f\"  Features reduced from {X_tr.shape[1]} ‚Üí {X_tr_clean.shape[1]}\")\n",
    "    print(f\"  CV Accuracy: {cv_scores.mean():.4f}\")\n",
    "    print(f\"  Test Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"  Test F1: {test_f1:.4f}\")\n",
    "    return X_tr_clean, X_te_clean\n",
    "\n",
    "# Evaluate all methods\n",
    "evaluate_features(X_train_encoded, X_test_encoded,\n",
    "                  y_train_encoded, y_test_encoded, \"Original (All Features)\")\n",
    "\n",
    "evaluate_features(X_train_mi, X_test_mi,\n",
    "                  y_train_encoded, y_test_encoded, \"Mutual Information (Top 15)\")\n",
    "\n",
    "evaluate_features(X_train_important, X_test_important,\n",
    "                  y_train_encoded, y_test_encoded, \"Feature Importance (Top 15)\")\n",
    "\n",
    "evaluate_features(X_train_interactions, X_test_interactions,\n",
    "                  y_train_encoded, y_test_encoded, \"With Interaction Features\")\n",
    "\n",
    "evaluate_features(X_train_grouped, X_test_grouped,\n",
    "                  y_train_encoded, y_test_encoded, \"With Grouped Features\")\n",
    "\n",
    "evaluate_features(X_train_pca, X_test_pca,\n",
    "                  y_train_encoded, y_test_encoded, \"PCA Extraction\")"
   ],
   "id": "d8a99c584b56a941",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "COMPARING FEATURE ENGINEERING METHODS\n",
      "============================================================\n",
      "\n",
      "Original (All Features):\n",
      "  Features reduced from 22 ‚Üí 15\n",
      "  CV Accuracy: 1.0000\n",
      "  Test Accuracy: 1.0000\n",
      "  Test F1: 1.0000\n",
      "\n",
      "Mutual Information (Top 15):\n",
      "  Features reduced from 13 ‚Üí 13\n",
      "  CV Accuracy: 1.0000\n",
      "  Test Accuracy: 1.0000\n",
      "  Test F1: 1.0000\n",
      "\n",
      "Feature Importance (Top 15):\n",
      "  Features reduced from 15 ‚Üí 15\n",
      "  CV Accuracy: 1.0000\n",
      "  Test Accuracy: 1.0000\n",
      "  Test F1: 1.0000\n",
      "\n",
      "With Interaction Features:\n",
      "  Features reduced from 27 ‚Üí 15\n",
      "  CV Accuracy: 1.0000\n",
      "  Test Accuracy: 1.0000\n",
      "  Test F1: 1.0000\n",
      "\n",
      "With Grouped Features:\n",
      "  Features reduced from 27 ‚Üí 15\n",
      "  CV Accuracy: 1.0000\n",
      "  Test Accuracy: 1.0000\n",
      "  Test F1: 1.0000\n",
      "\n",
      "PCA Extraction:\n",
      "  Features reduced from 10 ‚Üí 10\n",
      "  CV Accuracy: 0.9974\n",
      "  Test Accuracy: 0.9963\n",
      "  Test F1: 0.9963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(           PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n",
       " 0     0.559194  6.874120 -2.051207  1.618437 -1.435714 -1.293377 -0.499180   \n",
       " 1    -5.488872  1.379923 -0.083739  3.804188  1.958428  2.929394  0.839945   \n",
       " 2     2.355083 -5.419380  2.216657  2.636469  0.647546 -3.093522 -0.318050   \n",
       " 3    -6.783112 -0.766537  0.399875  0.332616 -2.642324 -1.394841 -0.557959   \n",
       " 4    -6.117552  1.944988  0.116055  1.209141  2.826867 -0.861422  1.353859   \n",
       " ...        ...       ...       ...       ...       ...       ...       ...   \n",
       " 6494 -6.629295 -0.727686 -0.311090 -0.049247 -2.888622  0.544776  1.619283   \n",
       " 6495  1.343031 -3.765500  0.462709  3.530793  0.091051  2.420432  1.959492   \n",
       " 6496  2.169395  0.991431  3.990295  0.764603 -1.960419  2.151598 -3.509326   \n",
       " 6497  4.876425 -3.392834 -2.307205 -0.069146 -1.305018  0.692595  1.396193   \n",
       " 6498  2.386398 -2.091909  0.514656 -0.904071 -1.105885 -1.492024 -0.879387   \n",
       " \n",
       "            PC8       PC9      PC10  \n",
       " 0    -1.029639  4.288116  1.181646  \n",
       " 1     1.844512 -3.462219 -0.777450  \n",
       " 2    -1.316694 -0.711184 -0.521781  \n",
       " 3    -0.106190 -0.697889  0.020207  \n",
       " 4    -0.749437 -0.376762  0.194670  \n",
       " ...        ...       ...       ...  \n",
       " 6494  0.044232  0.065537  0.043714  \n",
       " 6495 -3.008774  0.832870  1.385678  \n",
       " 6496 -2.228798 -0.989180 -0.363594  \n",
       " 6497  0.904905 -1.986051 -1.350591  \n",
       " 6498 -0.084440  0.783746 -1.622828  \n",
       " \n",
       " [6499 rows x 10 columns],\n",
       "            PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n",
       " 0     3.001443  0.156202 -2.625727 -1.837572  0.646774  0.551667  1.109295   \n",
       " 1     5.185679  1.238856  3.220820 -0.334852 -0.230689 -0.129111  3.028654   \n",
       " 2     1.817049  0.700723  3.280793  0.137807 -2.392511  3.250110 -0.353261   \n",
       " 3    -6.612552  0.376220  0.256267 -0.031925  3.783512 -1.581904  0.318945   \n",
       " 4     0.399376  6.283936 -0.266272 -1.042673 -1.718208  0.953916  0.960235   \n",
       " ...        ...       ...       ...       ...       ...       ...       ...   \n",
       " 1620 -6.930672 -0.725970  0.615309  0.857091 -1.297206 -0.208576  0.007610   \n",
       " 1621  4.501480 -4.103751  0.350564 -0.433945 -0.569713 -1.187350 -0.847007   \n",
       " 1622  0.399829 -2.534786 -0.616503 -3.448676 -0.574115 -0.046517  0.991457   \n",
       " 1623  1.320933 -1.469539  1.451873 -0.743969 -0.298839  0.954431 -2.933829   \n",
       " 1624  3.289955 -0.766708  0.486590 -2.401861  2.044144 -1.662256 -1.046795   \n",
       " \n",
       "            PC8       PC9      PC10  \n",
       " 0    -1.590732  0.959351  1.905375  \n",
       " 1    -1.410578 -0.582327  0.245260  \n",
       " 2    -1.263336 -0.517416 -0.674438  \n",
       " 3    -1.210330 -0.529226 -0.692619  \n",
       " 4    -0.298761  1.581000 -1.571746  \n",
       " ...        ...       ...       ...  \n",
       " 1620  0.951398 -0.364576 -0.343877  \n",
       " 1621 -0.699176  0.465269 -1.392129  \n",
       " 1622  0.846935  0.467053 -1.717522  \n",
       " 1623 -1.281438 -0.485645  1.404596  \n",
       " 1624 -0.427902 -0.127903  0.418755  \n",
       " \n",
       " [1625 rows x 10 columns])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T15:41:25.150435Z",
     "start_time": "2025-10-25T15:41:25.132667Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ========================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Identify best method (highest Test Accuracy)\n",
    "best_method = results_df.loc[results_df['Test Accuracy'].idxmax()]\n",
    "\n",
    "print(f\"\\nüèÜ Best Method: {best_method['Method']}\")\n",
    "print(f\"   Test Accuracy: {best_method['Test Accuracy']:.4f}\")\n",
    "print(f\"   CV Accuracy: {best_method['CV Accuracy']:.4f}\")\n",
    "print(f\"   Features Before: {int(best_method['Features Before'])}\")\n",
    "print(f\"   Features After: {int(best_method['Features After'])}\")"
   ],
   "id": "bbb94fca8758b26b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SUMMARY\n",
      "============================================================\n",
      "                     Method  Features Before  Features After  CV Accuracy  Test Accuracy  Test F1\n",
      "    Original (All Features)               22              15     1.000000       1.000000 1.000000\n",
      "Mutual Information (Top 15)               13              13     1.000000       1.000000 1.000000\n",
      "Feature Importance (Top 15)               15              15     1.000000       1.000000 1.000000\n",
      "  With Interaction Features               27              15     1.000000       1.000000 1.000000\n",
      "      With Grouped Features               27              15     1.000000       1.000000 1.000000\n",
      "             PCA Extraction               10              10     0.997384       0.996308 0.996308\n",
      "\n",
      "üèÜ Best Method: Original (All Features)\n",
      "   Test Accuracy: 1.0000\n",
      "   CV Accuracy: 1.0000\n",
      "   Features Before: 22\n",
      "   Features After: 15\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T15:41:26.030545Z",
     "start_time": "2025-10-25T15:41:25.306025Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ========================================\n",
    "#  SAVE BEST FEATURES FOR FINAL MODEL\n",
    "# ========================================\n",
    "print(\"\\n=== Saving Best Feature Set ===\")\n",
    "\n",
    "best_method_name = best_method['Method']\n",
    "print(f\"Detected best method: {best_method_name}\")\n",
    "\n",
    "if best_method_name == \"Original (All Features)\":\n",
    "    print(\"All methods performed equally well ‚Äì selecting Mutual Information (Top 15) for interpretability.\")\n",
    "    best_method_name = \"Mutual Information (Top 15)\"\n",
    "\n",
    "if 'Mutual Information' in best_method_name:\n",
    "    X_train_final, X_test_final = clean_features(X_train_encoded, X_test_encoded, y_train_encoded, k=15)\n",
    "    final_features = X_train_final.columns.tolist()\n",
    "\n",
    "elif 'Feature Importance' in best_method_name:\n",
    "    X_train_final, X_test_final = clean_features(X_train_encoded, X_test_encoded, y_train_encoded, k=15)\n",
    "    final_features = X_train_final.columns.tolist()\n",
    "\n",
    "elif 'Interaction' in best_method_name:\n",
    "    X_train_final = X_train_interactions\n",
    "    X_test_final = X_test_interactions\n",
    "    final_features = list(X_train_interactions.columns)\n",
    "\n",
    "elif 'Grouped' in best_method_name:\n",
    "    X_train_final = X_train_grouped\n",
    "    X_test_final = X_test_grouped\n",
    "    final_features = list(X_train_grouped.columns)\n",
    "\n",
    "elif 'PCA' in best_method_name:\n",
    "    X_train_final = X_train_pca\n",
    "    X_test_final = X_test_pca\n",
    "    final_features = pca_columns\n",
    "\n",
    "else:\n",
    "    X_train_final = X_train_encoded\n",
    "    X_test_final = X_test_encoded\n",
    "    final_features = list(X_train_encoded.columns)\n",
    "\n",
    "print(f\"Selected method: {best_method_name}\")\n",
    "print(f\"Features kept: {len(final_features)}\")\n",
    "print(f\"Final training shape: {X_train_final.shape}\")\n",
    "print(f\"Final test shape: {X_test_final.shape}\")"
   ],
   "id": "dfe31b48158185c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Saving Best Feature Set ===\n",
      "Detected best method: Original (All Features)\n",
      "All methods performed equally well ‚Äì selecting Mutual Information (Top 15) for interpretability.\n",
      "Selected method: Mutual Information (Top 15)\n",
      "Features kept: 15\n",
      "Final training shape: (6499, 15)\n",
      "Final test shape: (1625, 15)\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "###  Production Preprocessing and Pipeline\n",
    "\n",
    "All previous feature engineering steps were based on LabelEncoder-encoded data for exploration.\n",
    "To ensure the same preprocessing can be automatically applied during deployment (API inference),\n",
    "we now recreate the equivalent preprocessing logic using an OrdinalEncoder inside a scikit-learn\n",
    "Pipeline (encoding ‚Üí variance threshold ‚Üí SelectKBest).\n"
   ],
   "id": "5068bacc8e30c364"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T15:41:26.175201Z",
     "start_time": "2025-10-25T15:41:26.168602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Final training shape:\", X_train_final.shape)\n",
    "print(\"Final test shape:\", X_test_final.shape)"
   ],
   "id": "e626a7679bb013ee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final training shape: (6499, 15)\n",
      "Final test shape: (1625, 15)\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T15:41:27.170004Z",
     "start_time": "2025-10-25T15:41:26.325235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "categorical_features = X_train.columns.tolist()\n",
    "\n",
    "encoder = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ordinal', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', encoder, categorical_features)\n",
    "])\n",
    "\n",
    "prep_pipeline = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('variance', VarianceThreshold(threshold=0.01)),\n",
    "    ('select_kbest', SelectKBest(score_func=mutual_info_classif, k=15))\n",
    "])\n",
    "\n",
    "# Fit pipeline with target y for feature selection (mutual_info_classif needs y)\n",
    "prep_pipeline.fit(X_train, y_train_encoded)\n",
    "\n",
    "X_train_final = prep_pipeline.transform(X_train)\n",
    "X_test_final  = prep_pipeline.transform(X_test)\n",
    "\n",
    "print(f\"‚úì Preprocessing pipeline applied\")\n",
    "print(f\"Final training shape: {X_train_final.shape}\")\n",
    "print(f\"Final test shape: {X_test_final.shape}\")\n",
    "\n",
    "vt = prep_pipeline.named_steps['variance']\n",
    "skb = prep_pipeline.named_steps['select_kbest']\n",
    "\n",
    "mask_var = vt.get_support()                        # boolean mask over original columns\n",
    "names_after_var = [n for n, keep in zip(categorical_features, mask_var) if keep]\n",
    "\n",
    "mask_kbest = skb.get_support()                     # boolean mask over post-variance features\n",
    "selected_feature_names = [names_after_var[i] for i, keep in enumerate(mask_kbest) if keep]\n",
    "\n",
    "print(\"Selected feature names (k=15):\", selected_feature_names)\n",
    "\n",
    "\n",
    "prep_package = {\n",
    "    \"pipeline\": prep_pipeline,\n",
    "    \"original_feature_names\": categorical_features,        # hyphenated column names\n",
    "    \"selected_feature_names\": selected_feature_names,      # after variance + kbest\n",
    "    \"target_encoder\": y_encoder,                           # keep only y encoder\n",
    "    \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "}\n",
    "\n",
    "# Save pipeline\n",
    "joblib.dump(prep_package, \"artifacts/mushroom_preprocessing_pipeline.pkl\")\n",
    "joblib.dump(X_train_final, \"artifacts/X_train_final.pkl\")\n",
    "joblib.dump(X_test_final,  \"artifacts/X_test_final.pkl\")\n",
    "joblib.dump(y_train_encoded, \"artifacts/y_train_encoded.pkl\")\n",
    "joblib.dump(y_test_encoded,  \"artifacts/y_test_encoded.pkl\")\n",
    "print(\"‚úì Saved preprocessing artifacts to artifacts/\")"
   ],
   "id": "1d918410b74742d4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Preprocessing pipeline applied\n",
      "Final training shape: (6499, 15)\n",
      "Final test shape: (1625, 15)\n",
      "Selected feature names (k=15): ['cap-shape', 'bruises', 'odor', 'gill-spacing', 'gill-size', 'gill-color', 'stalk-root', 'stalk-surface-above-ring', 'stalk-surface-below-ring', 'stalk-color-above-ring', 'stalk-color-below-ring', 'ring-type', 'spore-print-color', 'population', 'habitat']\n",
      "‚úì Saved preprocessing artifacts to artifacts/\n"
     ]
    }
   ],
   "execution_count": 38
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
